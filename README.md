MATLAB Autoencoder for Signal Clustering and Analysis
Project Overview
This repository contains a suite of MATLAB scripts for training, evaluating, and testing convolutional autoencoders for unsupervised signal clustering. The primary goal is to identify an optimal autoencoder architecture that can effectively separate different classes of signals, even in the presence of noise.

The project employs a multi-objective optimization approach to select the best model, balancing two key objectives:

Low Reconstruction Error: The autoencoder's ability to accurately reconstruct the original signal from its compressed latent representation.

High Clustering Quality: The ability of the encoder's latent space to produce distinct, well-separated clusters corresponding to different signal classes.

The workflow is divided into three main phases:

Training: A grid search is performed over various hyperparameters to train a set of 40 different autoencoder models (data_and_train.m).

Evaluation and Selection: The trained models are evaluated using clustering metrics (Silhouette Score, Davies-Bouldin Index) and reconstruction error. A Pareto front analysis is used to identify the set of optimal models, and a single best model is selected (test_phase1.m).

Performance Testing: The best model is rigorously tested on signals corrupted with varying levels of noise (different Signal-to-Noise Ratios) to assess its robustness and classification performance (test2.m).

File Descriptions
Core Scripts
data_and_train.m: The main training script. It defines multiple autoencoder architectures, applies data augmentation, and trains 40 different models. It saves the trained networks and associated metadata to clustering_models_SNR_inc.mat.

test_phase1.m: The model evaluation and selection script. It loads the models trained by data_and_train.m, calculates clustering quality metrics, and uses Pareto front analysis to identify the best-performing model based on both reconstruction and clustering performance.

test2.m: The final performance testing script. It generates a test dataset with varying SNR levels, then evaluates the best model's ability to classify signals and reject unknown/noisy samples. It produces detailed performance figures, including confusion matrices and 3D error plots.

Utility Functions
daviesBouldin.m: A helper function to calculate the Davies-Bouldin Index, a metric for evaluating the quality of clustering results.

Data Files (Not Included)
combined_1000.mat: The initial dataset containing the signals to be clustered. This file must be present for the scripts to run.

clustering_models_SNR_inc.mat: Generated by data_and_train.m. Contains the 40 trained autoencoder and encoder networks, along with training history and parameters.

test_data.mat: Generated by test2.m. Contains the noisy signals, SNRs, and correlation values used for performance testing.

Methodology Workflow
The project follows a sequential workflow. Each script builds upon the output of the previous one.

1. Training Phase (data_and_train.m)
Data Loading & Preprocessing: Loads signals from combined_1000.mat and applies Z-score normalization.

Hyperparameter Grid Search: Defines a set of hyperparameters to explore, including different latent space dimensions, convolutional filter sizes, kernel sizes, and levels of noise for data augmentation.

Model Training: Iterates through the hyperparameter combinations to train 40 unique 1D convolutional autoencoder models.

Encoder Extraction: For each full autoencoder, a corresponding encoder network (from input to the latent bottleneck) is extracted.

Output: Saves all trained models, encoders, training history, and final validation loss into clustering_models_SNR_inc.mat.

2. Evaluation & Selection Phase (test_phase1.m)
Model Loading: Loads the 40 models from clustering_models_SNR_inc.mat.

Clustering Metric Calculation: For each model, the script:

Encodes the training data into the latent space.

Calculates the Silhouette Score and Davies-Bouldin Index to quantify cluster separation.

Pareto Front Analysis:

A "Unified Cluster Quality Score" is computed from the normalized clustering metrics.

A Pareto front is plotted to visualize the trade-off between Reconstruction Error (objective 1, lower is better) and the Unified Cluster Quality Score (objective 2, higher is better).

The script identifies the non-dominated models that lie on the Pareto front.

Best Model Selection: The script automatically selects the single best model from the Pareto front by finding the point closest to the "Utopian Point" (zero reconstruction error and perfect cluster score).

3. Performance Testing Phase (test2.m)
Noisy Data Generation: Creates a comprehensive test set by adding various levels of Gaussian noise to the original signals, resulting in a wide range of Signal-to-Noise Ratios (SNRs).

Model Evaluation under Noise: The selected best model is used to:

Reconstruct the noisy signals and calculate reconstruction errors for each SNR level.

Embed the noisy signals into the latent space using the encoder.

Classify the signals by finding the nearest cluster centroid in the latent space. A reconstruction error threshold is used to reject signals that are too noisy or anomalous.

Performance Metrics: Calculates the Macro F1-score and confusion matrices to evaluate classification accuracy across all noise levels.

Visualization: Generates and saves detailed figures in the performance_results folder, including:

3D scatter plots of reconstruction error vs. SNR.

Confusion charts for classification results.

Plots of reconstruction error for each signal class.

How to Run
Prerequisites:

MATLAB environment.

Deep Learning Toolbox.

Statistics and Machine Learning Toolbox.

Ensure the dataset combined_1000.mat is in the MATLAB path.

Execution Order: Run the scripts in the following order:

% 1. Train all models
run('data_and_train.m');

% 2. Evaluate models and select the best one from the Pareto front
run('test_phase1.m');

% 3. Test the performance of the selected model against noisy data
run('test2.m');

Outputs
clustering_models_SNR_inc.mat: A file containing all trained networks.

test_data.mat: A file containing the generated noisy test dataset.

Figures: The scripts will generate several figures and save them to the following folders, which are created automatically:

reconstruction_quality_figures/: Contains reconstruction quality plots for each of the 40 models from the training phase.

latent_quality_figures/: (Currently commented out) Intended for t-SNE visualizations of the latent space.

performance_results/: Contains detailed performance analysis plots (confusion matrices, 3D scatter plots, etc.) for the best model from the testing phase.
